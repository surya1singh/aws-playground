{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51e2984e-b528-4cb8-8168-9b6de58a40ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading to /home/jovyan/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/2.archive...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42.6M/42.6M [00:01<00:00, 25.3MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /home/jovyan/.cache/kagglehub/datasets/olistbr/brazilian-ecommerce/versions/2\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "path = kagglehub.dataset_download(\"olistbr/brazilian-ecommerce\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9a89c3-ece2-4338-8c60-96dbe4ddd5e1",
   "metadata": {},
   "source": [
    "# Read CSV \n",
    "\n",
    "Read csv from data folder and create pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae6379e3-c3e0-4105-8b6a-c68c108023ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb6d73c3-54f4-4cc1-85a3-10933f713ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from faker import Faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "652087ee-b6a3-4f94-aaa4-5ae7d07eb111",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import uuid\n",
    "import random\n",
    "from dataclasses import dataclass\n",
    "from datetime import date, datetime, timedelta\n",
    "from typing import Dict, List, Tuple, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b91f6b2-4caa-4ca5-871b-8faef6d230ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fake = Faker()\n",
    "Faker.seed(7)\n",
    "random.seed(7)\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "616d002a-ba7e-48a1-9a0e-c51fde8d2dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class GenConfig:\n",
    "    olist_dir: str\n",
    "    out_dir: str = \"output\"\n",
    "    start_date: date = date(2019,1,1)\n",
    "    num_days: int = 15\n",
    "\n",
    "    # daily change rate (dims)\n",
    "    customer_change_rate: float = 0.01\n",
    "    customer_delete_rate: float = 0.001\n",
    "    customer_insert_rate: float = 0.002\n",
    "\n",
    "    product_change_rate: float = 0.005\n",
    "    product_delete_rate: float = 0.0005\n",
    "    product_insert_rate: float = 0.001\n",
    "\n",
    "    #daily fact generation scale\n",
    "    new_orders_per_day: int = 1500\n",
    "    return_rate: float = 0.03\n",
    "    cancel_rate: float = 0.01\n",
    "\n",
    "    # inventory behaviour\n",
    "    restock_prob_per_product_per_day: float = 0.0008\n",
    "    restock_qty_min: int = 20\n",
    "    restock_qty_max: int = 300\n",
    "\n",
    "    file_format: str = \"csv\"\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "d86c16b0-cd18-4450-ab3c-4489a87eed6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = GenConfig(\n",
    "        olist_dir=r\"data\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a1f7f8-3e10-48d5-88d0-361a48355e03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8cfe19ee-844c-465f-b9ec-4cce7f74f69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_olist(cfg: GenConfig) -> Dict[str: pd.DataFrame]:\n",
    "    d = {}\n",
    "    base = cfg.olist_dir\n",
    "\n",
    "    def r(name: str) -> pd.DataFrame:\n",
    "        return pd.read_csv(os.path.join(base, name))\n",
    "\n",
    "    d[\"customer\"] = r(\"olist_customers_dataset.csv\")\n",
    "    d[\"orders\"] = r(\"olist_orders_dataset.csv\")\n",
    "    d[\"order_items\"] = r(\"olist_order_items_dataset.csv\")\n",
    "    d[\"products\"] = r(\"olist_products_dataset.csv\")\n",
    "    d[\"payments\"] = r(\"olist_order_payments_dataset.csv\")\n",
    "    d[\"reviews\"] = r(\"olist_order_reviews_dataset.csv\")\n",
    "    d[\"sellers\"] = r(\"olist_sellers_dataset.csv\")\n",
    "    d[\"geolocation\"] = r(\"olist_geolocation_dataset.csv\")\n",
    "    d[\"category_translation\"] = r(\"product_category_name_translation.csv\")\n",
    "\n",
    "    # Normalize timestamps\n",
    "    for col in [\n",
    "        \"order_purchase_timestamp\",\n",
    "        \"order_approved_at\",\n",
    "        \"order_delivered_carrier_date\",\n",
    "        \"order_delivered_customer_date\",\n",
    "        \"order_estimated_delivery_date\",\n",
    "    ]:\n",
    "        if col in d[\"orders\"].columns:\n",
    "            d[\"orders\"][col] = pd.to_datetime(d[\"orders\"][col], errors=\"coerce\")\n",
    "\n",
    "    return d\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6d79aa7b-e3a4-4156-9a1e-ca01dda6f5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "olist_data = load_olist(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac9c9bf-a8d1-4485-84fa-ab16a27714ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "24c50533-ee5f-4de3-b5cc-4dc7dd36b04b",
   "metadata": {},
   "source": [
    "# Create tables data\n",
    "* customers\n",
    "* customer_addresses\n",
    "* customer_accounts\n",
    "* products\n",
    "* product_categories\n",
    "* suppliers\n",
    "* inventory\n",
    "* orders\n",
    "* order_items\n",
    "* payments\n",
    "* shipments\n",
    "* returns\n",
    "\n",
    "Customers, products, and suppliers are baseline tables.\n",
    "first create them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e68fc8d1-da86-45fa-bff3-c8360cfa938c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>customer_unique_id</th>\n",
       "      <th>customer_zip_code_prefix</th>\n",
       "      <th>customer_city</th>\n",
       "      <th>customer_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>06b8999e2fba1a1fbc88172c00ba8bc7</td>\n",
       "      <td>861eff4711a542e4b93843c6dd7febb0</td>\n",
       "      <td>14409</td>\n",
       "      <td>franca</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18955e83d337fd6b2def6b18a428ac77</td>\n",
       "      <td>290c77bc529b7ac935b93aa66c333dc3</td>\n",
       "      <td>9790</td>\n",
       "      <td>sao bernardo do campo</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4e7b3e00288586ebd08712fdd0374a03</td>\n",
       "      <td>060e732b5b29e8181a18229c7b0b2b5e</td>\n",
       "      <td>1151</td>\n",
       "      <td>sao paulo</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b2b6027bc5c5109e529d4dc6358b12c3</td>\n",
       "      <td>259dac757896d24d7702b9acbbff3f3c</td>\n",
       "      <td>8775</td>\n",
       "      <td>mogi das cruzes</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4f2d8ab171c80ec8364f7c12e35b23ad</td>\n",
       "      <td>345ecd01c38d18a9036ed96c73b8d066</td>\n",
       "      <td>13056</td>\n",
       "      <td>campinas</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99436</th>\n",
       "      <td>17ddf5dd5d51696bb3d7c6291687be6f</td>\n",
       "      <td>1a29b476fee25c95fbafc67c5ac95cf8</td>\n",
       "      <td>3937</td>\n",
       "      <td>sao paulo</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99437</th>\n",
       "      <td>e7b71a9017aa05c9a7fd292d714858e8</td>\n",
       "      <td>d52a67c98be1cf6a5c84435bd38d095d</td>\n",
       "      <td>6764</td>\n",
       "      <td>taboao da serra</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99438</th>\n",
       "      <td>5e28dfe12db7fb50a4b2f691faecea5e</td>\n",
       "      <td>e9f50caf99f032f0bf3c55141f019d99</td>\n",
       "      <td>60115</td>\n",
       "      <td>fortaleza</td>\n",
       "      <td>CE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99439</th>\n",
       "      <td>56b18e2166679b8a959d72dd06da27f9</td>\n",
       "      <td>73c2643a0a458b49f58cea58833b192e</td>\n",
       "      <td>92120</td>\n",
       "      <td>canoas</td>\n",
       "      <td>RS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99440</th>\n",
       "      <td>274fa6071e5e17fe303b9748641082c8</td>\n",
       "      <td>84732c5050c01db9b23e19ba39899398</td>\n",
       "      <td>6703</td>\n",
       "      <td>cotia</td>\n",
       "      <td>SP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99441 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            customer_id                customer_unique_id  \\\n",
       "0      06b8999e2fba1a1fbc88172c00ba8bc7  861eff4711a542e4b93843c6dd7febb0   \n",
       "1      18955e83d337fd6b2def6b18a428ac77  290c77bc529b7ac935b93aa66c333dc3   \n",
       "2      4e7b3e00288586ebd08712fdd0374a03  060e732b5b29e8181a18229c7b0b2b5e   \n",
       "3      b2b6027bc5c5109e529d4dc6358b12c3  259dac757896d24d7702b9acbbff3f3c   \n",
       "4      4f2d8ab171c80ec8364f7c12e35b23ad  345ecd01c38d18a9036ed96c73b8d066   \n",
       "...                                 ...                               ...   \n",
       "99436  17ddf5dd5d51696bb3d7c6291687be6f  1a29b476fee25c95fbafc67c5ac95cf8   \n",
       "99437  e7b71a9017aa05c9a7fd292d714858e8  d52a67c98be1cf6a5c84435bd38d095d   \n",
       "99438  5e28dfe12db7fb50a4b2f691faecea5e  e9f50caf99f032f0bf3c55141f019d99   \n",
       "99439  56b18e2166679b8a959d72dd06da27f9  73c2643a0a458b49f58cea58833b192e   \n",
       "99440  274fa6071e5e17fe303b9748641082c8  84732c5050c01db9b23e19ba39899398   \n",
       "\n",
       "       customer_zip_code_prefix          customer_city customer_state  \n",
       "0                         14409                 franca             SP  \n",
       "1                          9790  sao bernardo do campo             SP  \n",
       "2                          1151              sao paulo             SP  \n",
       "3                          8775        mogi das cruzes             SP  \n",
       "4                         13056               campinas             SP  \n",
       "...                         ...                    ...            ...  \n",
       "99436                      3937              sao paulo             SP  \n",
       "99437                      6764        taboao da serra             SP  \n",
       "99438                     60115              fortaleza             CE  \n",
       "99439                     92120                 canoas             RS  \n",
       "99440                      6703                  cotia             SP  \n",
       "\n",
       "[99441 rows x 5 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "olist_data[\"customer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6a48faef-810c-4c11-80b3-f19613e4f247",
   "metadata": {},
   "outputs": [],
   "source": [
    "customers = olist_data[\"customer\"].copy()\n",
    "customers[\"created_ts\"] = pd.Timestamp(\"2017-01-01\")\n",
    "customers[\"last_updated_ts\"] = pd.Timestamp(\"2017-01-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "488668de-4514-4345-bd17-27bdbc4a7ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "products = olist_data[\"products\"].copy()\n",
    "products[\"created_ts\"] = pd.Timestamp(\"2017-01-01\")\n",
    "products[\"last_updated_ts\"] = pd.Timestamp(\"2017-01-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d2a32913-0af9-4040-951d-78ac292594ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_suppliers_from_sellers(sellers: pd.DataFrame) -> pd.DataFrame:\n",
    "    sup = sellers.copy()\n",
    "    sup = sup.rename(columns={\n",
    "        \"seller_id\": \"supplier_id\",\n",
    "        \"seller_zip_code_prefix\": \"zip_code_prefix\",\n",
    "        \"seller_city\": \"city\",\n",
    "        \"seller_state\": \"state\" \n",
    "    })\n",
    "    sup[\"supplier_status\"] = \"ACTIVE\"\n",
    "    sup[\"created_ts\"] = pd.Timestamp(\"2017-01-01\")\n",
    "    sup[\"last_updated_ts\"] = pd.Timestamp(\"2017-01-01\")\n",
    "    return sup[[\"supplier_id\", \"zip_code_prefix\", \"city\", \"state\", \"supplier_status\", \"created_ts\", \"last_updated_ts\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "75f21ede-9c20-479a-8097-f3b5b1bd8066",
   "metadata": {},
   "outputs": [],
   "source": [
    "suppliers = build_suppliers_from_sellers(olist_data[\"sellers\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "94904c50-ecd4-46eb-ad1f-a84589dd0033",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_customer_addresses(customers: pd.DataFrame) -> pd.DataFrame:\n",
    "    addr = customers[[\"customer_id\", \"customer_zip_code_prefix\", \"customer_city\", \"customer_state\"]].copy()\n",
    "    addr = addr.rename(columns = {\n",
    "        \"customer_zip_code_prefix\": \"zip_code_prefix\",\n",
    "        \"customer_city\": \"city\",\n",
    "        \"customer_state\": \"state\"\n",
    "    })\n",
    "    addr[\"address_id\"] = [str(uuid.uuid4()) for _ in range(len(addr))]\n",
    "    addr[\"address_line1\"] = [fake.street_address() for _ in range(len(addr))]\n",
    "    addr[\"address_line2\"] = [fake.secondary_address() for _ in range(len(addr))]\n",
    "    addr[\"created_ts\"] = pd.Timestamp(\"2017-01-01\")\n",
    "    addr[\"last_updated_ts\"] = pd.Timestamp(\"2017-01-01\")\n",
    "    return addr[[\"address_id\",\"customer_id\", \"address_line1\", \"address_line2\", \"zip_code_prefix\",\n",
    "                 \"city\", \"state\", \"created_ts\", \"last_updated_ts\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e9f4d5-18a1-475b-92f4-77320f2f0c76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0a2443da-5047-4de9-a3af-7a76e02ce8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_addresses = build_customer_addresses(customers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "35ef00f0-1be1-4d2e-a911-b4eca5e701f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>address_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>address_line1</th>\n",
       "      <th>address_line2</th>\n",
       "      <th>zip_code_prefix</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>created_ts</th>\n",
       "      <th>last_updated_ts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3f9c1f0f-2a0e-4ba6-a744-79f53a02f6ea</td>\n",
       "      <td>06b8999e2fba1a1fbc88172c00ba8bc7</td>\n",
       "      <td>37328 Johnson Lake Apt. 884</td>\n",
       "      <td>Suite 709</td>\n",
       "      <td>14409</td>\n",
       "      <td>franca</td>\n",
       "      <td>SP</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>2017-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fa9debac-518d-4ecb-8f20-bac32c7c80cb</td>\n",
       "      <td>18955e83d337fd6b2def6b18a428ac77</td>\n",
       "      <td>949 Duran Ville Apt. 791</td>\n",
       "      <td>Suite 964</td>\n",
       "      <td>9790</td>\n",
       "      <td>sao bernardo do campo</td>\n",
       "      <td>SP</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>2017-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8b17e525-e3e9-41fe-9228-9890c85f22cb</td>\n",
       "      <td>4e7b3e00288586ebd08712fdd0374a03</td>\n",
       "      <td>49652 Kelly Summit</td>\n",
       "      <td>Suite 667</td>\n",
       "      <td>1151</td>\n",
       "      <td>sao paulo</td>\n",
       "      <td>SP</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>2017-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9070f0e5-038a-433b-96c1-b4dc3d7f7b35</td>\n",
       "      <td>b2b6027bc5c5109e529d4dc6358b12c3</td>\n",
       "      <td>54512 Nancy Station</td>\n",
       "      <td>Apt. 331</td>\n",
       "      <td>8775</td>\n",
       "      <td>mogi das cruzes</td>\n",
       "      <td>SP</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>2017-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2cb4d314-280f-4b37-89f9-3c07001a10a6</td>\n",
       "      <td>4f2d8ab171c80ec8364f7c12e35b23ad</td>\n",
       "      <td>4391 Williams Landing Suite 394</td>\n",
       "      <td>Apt. 516</td>\n",
       "      <td>13056</td>\n",
       "      <td>campinas</td>\n",
       "      <td>SP</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>2017-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99436</th>\n",
       "      <td>c22ccad6-4ac5-479a-acdd-8a08205c5d0f</td>\n",
       "      <td>17ddf5dd5d51696bb3d7c6291687be6f</td>\n",
       "      <td>2806 Chris Dam Apt. 954</td>\n",
       "      <td>Apt. 931</td>\n",
       "      <td>3937</td>\n",
       "      <td>sao paulo</td>\n",
       "      <td>SP</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>2017-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99437</th>\n",
       "      <td>3810bd1a-44ea-41b2-8f7f-65c2151c3e2c</td>\n",
       "      <td>e7b71a9017aa05c9a7fd292d714858e8</td>\n",
       "      <td>7613 Edward Spring Apt. 859</td>\n",
       "      <td>Apt. 426</td>\n",
       "      <td>6764</td>\n",
       "      <td>taboao da serra</td>\n",
       "      <td>SP</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>2017-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99438</th>\n",
       "      <td>72e14e41-ba22-4289-8578-1a95af2c8d52</td>\n",
       "      <td>5e28dfe12db7fb50a4b2f691faecea5e</td>\n",
       "      <td>590 Hamilton Camp Apt. 437</td>\n",
       "      <td>Suite 704</td>\n",
       "      <td>60115</td>\n",
       "      <td>fortaleza</td>\n",
       "      <td>CE</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>2017-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99439</th>\n",
       "      <td>19fe647f-2a9c-4862-84ac-77bb9a4a1fcd</td>\n",
       "      <td>56b18e2166679b8a959d72dd06da27f9</td>\n",
       "      <td>25971 Robert Ramp Suite 536</td>\n",
       "      <td>Suite 826</td>\n",
       "      <td>92120</td>\n",
       "      <td>canoas</td>\n",
       "      <td>RS</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>2017-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99440</th>\n",
       "      <td>ded55ab7-4818-46c4-8cc2-11a08e536b60</td>\n",
       "      <td>274fa6071e5e17fe303b9748641082c8</td>\n",
       "      <td>022 Peterson Mountain Apt. 439</td>\n",
       "      <td>Suite 009</td>\n",
       "      <td>6703</td>\n",
       "      <td>cotia</td>\n",
       "      <td>SP</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>2017-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99441 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 address_id                       customer_id  \\\n",
       "0      3f9c1f0f-2a0e-4ba6-a744-79f53a02f6ea  06b8999e2fba1a1fbc88172c00ba8bc7   \n",
       "1      fa9debac-518d-4ecb-8f20-bac32c7c80cb  18955e83d337fd6b2def6b18a428ac77   \n",
       "2      8b17e525-e3e9-41fe-9228-9890c85f22cb  4e7b3e00288586ebd08712fdd0374a03   \n",
       "3      9070f0e5-038a-433b-96c1-b4dc3d7f7b35  b2b6027bc5c5109e529d4dc6358b12c3   \n",
       "4      2cb4d314-280f-4b37-89f9-3c07001a10a6  4f2d8ab171c80ec8364f7c12e35b23ad   \n",
       "...                                     ...                               ...   \n",
       "99436  c22ccad6-4ac5-479a-acdd-8a08205c5d0f  17ddf5dd5d51696bb3d7c6291687be6f   \n",
       "99437  3810bd1a-44ea-41b2-8f7f-65c2151c3e2c  e7b71a9017aa05c9a7fd292d714858e8   \n",
       "99438  72e14e41-ba22-4289-8578-1a95af2c8d52  5e28dfe12db7fb50a4b2f691faecea5e   \n",
       "99439  19fe647f-2a9c-4862-84ac-77bb9a4a1fcd  56b18e2166679b8a959d72dd06da27f9   \n",
       "99440  ded55ab7-4818-46c4-8cc2-11a08e536b60  274fa6071e5e17fe303b9748641082c8   \n",
       "\n",
       "                         address_line1 address_line2  zip_code_prefix  \\\n",
       "0          37328 Johnson Lake Apt. 884     Suite 709            14409   \n",
       "1             949 Duran Ville Apt. 791     Suite 964             9790   \n",
       "2                   49652 Kelly Summit     Suite 667             1151   \n",
       "3                  54512 Nancy Station      Apt. 331             8775   \n",
       "4      4391 Williams Landing Suite 394      Apt. 516            13056   \n",
       "...                                ...           ...              ...   \n",
       "99436          2806 Chris Dam Apt. 954      Apt. 931             3937   \n",
       "99437      7613 Edward Spring Apt. 859      Apt. 426             6764   \n",
       "99438       590 Hamilton Camp Apt. 437     Suite 704            60115   \n",
       "99439      25971 Robert Ramp Suite 536     Suite 826            92120   \n",
       "99440   022 Peterson Mountain Apt. 439     Suite 009             6703   \n",
       "\n",
       "                        city state created_ts last_updated_ts  \n",
       "0                     franca    SP 2017-01-01      2017-01-01  \n",
       "1      sao bernardo do campo    SP 2017-01-01      2017-01-01  \n",
       "2                  sao paulo    SP 2017-01-01      2017-01-01  \n",
       "3            mogi das cruzes    SP 2017-01-01      2017-01-01  \n",
       "4                   campinas    SP 2017-01-01      2017-01-01  \n",
       "...                      ...   ...        ...             ...  \n",
       "99436              sao paulo    SP 2017-01-01      2017-01-01  \n",
       "99437        taboao da serra    SP 2017-01-01      2017-01-01  \n",
       "99438              fortaleza    CE 2017-01-01      2017-01-01  \n",
       "99439                 canoas    RS 2017-01-01      2017-01-01  \n",
       "99440                  cotia    SP 2017-01-01      2017-01-01  \n",
       "\n",
       "[99441 rows x 9 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer_addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "3d38c900-a77a-4f66-a70e-64dbe578d8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_customer_accounts(customers: pd.DataFrame) -> pd.DataFrame:\n",
    "    acct = pd.DataFrame({\n",
    "        \"account_id\": [str(uuid.uuid4()) for _ in range(len(customers))],\n",
    "        \"customer_id\": customers[\"customer_id\"].values,\n",
    "        \"account_status\": np.where(np.random.rand(len(customers)) < 0.98, \"ACTIVE\", \"SUSPENDED\"),\n",
    "        \"created_ts\": pd.Timestamp(\"2017-01-01\"),\n",
    "        \"last_updated_ts\": pd.Timestamp(\"2017-01-01\")\n",
    "    })\n",
    "    return acct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "0ff1f935-faf8-40fc-ad34-4a578eface5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_accounts = build_customer_accounts(customers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32eb4b78-a82d-4afd-b645-920d7310134e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9986d9d3-a7c2-45e2-b684-5451a977e369",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_inventory(products: pd.DataFrame) -> pd.DataFrame:\n",
    "    inv = pd.DataFrame({\n",
    "        \"product_id\": products[\"product_id\"].values,\n",
    "        \"on_hand_qty\": np.random.randint(10, 500, size=len(products)),\n",
    "        \"reserved_qty\": np.random.randint(0, 20, size = len(products)),\n",
    "        \"warehouse_id\": np.random.choice([\"WH1\", \"WH2\", \"WH3\"], size = len(products)),\n",
    "        \"created_ts\": pd.Timestamp(\"2017-01-01\"),\n",
    "        \"last_updated_ts\": pd.Timestamp(\"2017-01-01\")\n",
    "    })\n",
    "    return inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f0676218-6e68-455c-bccd-730ec331e959",
   "metadata": {},
   "outputs": [],
   "source": [
    "inventory = build_inventory(products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "495bb4e6-36cf-4831-866d-d8ee0a3f11c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>on_hand_qty</th>\n",
       "      <th>reserved_qty</th>\n",
       "      <th>warehouse_id</th>\n",
       "      <th>created_ts</th>\n",
       "      <th>last_updated_ts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1e9e8ef04dbcff4541ed26657ea517e5</td>\n",
       "      <td>124</td>\n",
       "      <td>10</td>\n",
       "      <td>WH1</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>2017-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3aa071139cb16b67ca9e5dea641aaa2f</td>\n",
       "      <td>57</td>\n",
       "      <td>3</td>\n",
       "      <td>WH3</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>2017-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>96bd76ec8810374ed1b65e291975717f</td>\n",
       "      <td>336</td>\n",
       "      <td>18</td>\n",
       "      <td>WH3</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>2017-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cef67bcfe19066a932b7673e239eb23d</td>\n",
       "      <td>422</td>\n",
       "      <td>17</td>\n",
       "      <td>WH2</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>2017-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9dc1a7de274444849c219cff195d0b71</td>\n",
       "      <td>142</td>\n",
       "      <td>16</td>\n",
       "      <td>WH2</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>2017-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32946</th>\n",
       "      <td>a0b7d5a992ccda646f2d34e418fff5a0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>WH3</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>2017-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32947</th>\n",
       "      <td>bf4538d88321d0fd4412a93c974510e6</td>\n",
       "      <td>164</td>\n",
       "      <td>2</td>\n",
       "      <td>WH3</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>2017-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32948</th>\n",
       "      <td>9a7c6041fa9592d9d9ef6cfe62a71f8c</td>\n",
       "      <td>398</td>\n",
       "      <td>10</td>\n",
       "      <td>WH1</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>2017-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32949</th>\n",
       "      <td>83808703fc0706a22e264b9d75f04a2e</td>\n",
       "      <td>233</td>\n",
       "      <td>9</td>\n",
       "      <td>WH2</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>2017-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32950</th>\n",
       "      <td>106392145fca363410d287a815be6de4</td>\n",
       "      <td>185</td>\n",
       "      <td>12</td>\n",
       "      <td>WH3</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>2017-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32951 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             product_id  on_hand_qty  reserved_qty  \\\n",
       "0      1e9e8ef04dbcff4541ed26657ea517e5          124            10   \n",
       "1      3aa071139cb16b67ca9e5dea641aaa2f           57             3   \n",
       "2      96bd76ec8810374ed1b65e291975717f          336            18   \n",
       "3      cef67bcfe19066a932b7673e239eb23d          422            17   \n",
       "4      9dc1a7de274444849c219cff195d0b71          142            16   \n",
       "...                                 ...          ...           ...   \n",
       "32946  a0b7d5a992ccda646f2d34e418fff5a0           13             1   \n",
       "32947  bf4538d88321d0fd4412a93c974510e6          164             2   \n",
       "32948  9a7c6041fa9592d9d9ef6cfe62a71f8c          398            10   \n",
       "32949  83808703fc0706a22e264b9d75f04a2e          233             9   \n",
       "32950  106392145fca363410d287a815be6de4          185            12   \n",
       "\n",
       "      warehouse_id created_ts last_updated_ts  \n",
       "0              WH1 2017-01-01      2017-01-01  \n",
       "1              WH3 2017-01-01      2017-01-01  \n",
       "2              WH3 2017-01-01      2017-01-01  \n",
       "3              WH2 2017-01-01      2017-01-01  \n",
       "4              WH2 2017-01-01      2017-01-01  \n",
       "...            ...        ...             ...  \n",
       "32946          WH3 2017-01-01      2017-01-01  \n",
       "32947          WH3 2017-01-01      2017-01-01  \n",
       "32948          WH1 2017-01-01      2017-01-01  \n",
       "32949          WH2 2017-01-01      2017-01-01  \n",
       "32950          WH3 2017-01-01      2017-01-01  \n",
       "\n",
       "[32951 rows x 6 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inventory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f8776ca2-9ec5-4e63-92a0-53d2ca856029",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_orders = olist_data[\"orders\"].copy()\n",
    "base_order_items = olist_data[\"order_items\"].copy()\n",
    "base_payments = olist_data[\"payments\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "0ff07e27-9109-4ba8-b10e-895508f5a194",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_shipments_from_orders(orders: pd.DataFrame) -> pd.DataFrame:\n",
    "    shp = pd.DataFrame({\n",
    "        \"shipment_id\": [str(uuid.uuid4()) for _ in range(len(orders))],\n",
    "        \"order_id\": orders[\"order_id\"].values,\n",
    "        \"shipment_status\": np.where(orders[\"order_status\"].isin([\"delivered\"]), \n",
    "                                         \"DELIVERED\",\n",
    "                                         np.where(orders[\"order_status\"].isin([\"shipped\"]), \n",
    "                                                  \"SHIPPED\",\n",
    "                                                  np.where(orders[\"order_status\"].isin([\"canceled\"]), \n",
    "                                                           \"CANCELED\", \n",
    "                                                           \"CREATED\"))),\n",
    "        \"shipping_created_ts\": orders[\"order_purchase_timestamp\"].values,\n",
    "        \"shipped_ts\": orders[\"order_delivered_carrier_date\"].values,\n",
    "        \"delivered_ts\": orders[\"order_delivered_customer_date\"].values,\n",
    "        \"carrier\": np.random.choice([\"Correios\", \"Loggi\", \"Jadlog\", \"TotalExpress\"], size=len(orders)),\n",
    "        \"tracking_number\": [fake.bothify(text=\"BR###########\") for _ in range(len(orders))]\n",
    "    })\n",
    "    shp[\"created_ts\"] = shp[\"shipping_created_ts\"]\n",
    "    shp[\"last_updated_ts\"] = shp[[\"shipping_created_ts\", \"shipped_ts\", \"delivered_ts\"]].max(axis=1)\n",
    "    return shp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "529c3655-bd1d-4535-bc4e-c0ab2d8ebfbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_shipments = build_shipments_from_orders(base_orders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "e530e7ad-9012-42ed-a473-0c74ddba2be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_returns_from_orders_reviews(orders: pd.DataFrame, reviews: pd.DataFrame, cfg: GenConfig) -> pd.DataFrame:\n",
    "    delivered = orders[orders[\"order_status\"] == \"delivered\"].copy()\n",
    "    delivered = delivered.merge(reviews[[\"order_id\", \"review_score\"]], on=\"order_id\", how = \"left\")\n",
    "    delivered[\"delivery_delay_days\"] = (\n",
    "             (delivered[\"order_delivered_customer_date\"] - delivered[\"order_purchase_timestamp\"])\n",
    "        .dt.total_seconds()/86400).fillna(0)\n",
    "\n",
    "    # probabilty boost: bad reviews + long delay\n",
    "    base_p = cfg.return_rate\n",
    "    score = delivered[\"review_score\"].fillna(5)\n",
    "    delay = delivered[\"delivery_delay_days\"].clip(0,60)\n",
    "    p = base_p + (5 - score)*0.01 + (delay/60) * 0.02\n",
    "    p = p.clip(0, 0.25)\n",
    "\n",
    "    mask = np.random.rand(len(delivered)) < p.values\n",
    "    ret_orders = delivered[mask].copy()\n",
    "\n",
    "    if ret_orders.empty:\n",
    "        return pd.DataFrame(columns = [\n",
    "            \"return_id\", \"order_id\", \"return_ts\", \"return_reson\",\n",
    "            \"refund_amount\", \"created_ts\", \"last_updated_ts\"\n",
    "        ])\n",
    "\n",
    "    return_ts = (ret_orders[\"order_delivered_customer_date\"].fillna(ret_orders[\"order_purchase_timestamp\"])\n",
    "                 + pd.to_timedelta(np.random.randint(1, 21, size = len(ret_orders)), unit=\"D\"))\n",
    "\n",
    "    returns = pd.DataFrame({\n",
    "        \"return_id\": [str(uuid.uuid4()) for _ in range(len(ret_orders))],\n",
    "        \"order_id\": ret_orders[\"order_id\"].values,\n",
    "        \"return_ts\": return_ts.values,\n",
    "        \"return_reason\": np.random.choice(\n",
    "            [\"DAMAGED\", \"NOT_AS_DESCRIBED\", \"LATE_DELIVERY\", \"WRONG_ITEM\", \"CHANGED_MIND\"],\n",
    "            size=len(ret_orders),\n",
    "            p=[0.25, 0.25, 0.20, 0.10, 0.20]\n",
    "        ),\n",
    "        \"refund_amount\": np.random.uniform(5.0, 250.0, size=len(ret_orders)).round(2),\n",
    "    })\n",
    "    returns[\"created_ts\"] = returns[\"return_ts\"]\n",
    "    returns[\"last_updated_ts\"] = returns[\"return_ts\"]\n",
    "    return returns\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "4b025b64-7303-4315-9add-108c054bb903",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_returns = build_returns_from_orders_reviews(base_orders, olist_data[\"reviews\"], cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db99290d-181d-40e8-aa8b-32c12e9a3e7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "56b4a72c-6ce2-41b1-b728-ae08191424ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For daily snapshots, we maintain \"current state\" for dims/state tables\n",
    "cur = {\n",
    "    \"customers\": customers,\n",
    "    \"customer_addresses\": customer_addresses,\n",
    "    \"customer_accounts\": customer_accounts,\n",
    "    \"products\": products,\n",
    "    \"suppliers\": suppliers,\n",
    "    \"inventory\": inventory,\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "1d6b9754-f34e-451b-8597-10d9394cb3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Facts accumulate day by day (append)\n",
    "facts = {\n",
    "    \"orders\": base_orders.copy(),\n",
    "    \"order_items\": base_order_items.copy(),\n",
    "    \"payments\": base_payments.copy(),\n",
    "    \"shipments\": base_shipments.copy(),\n",
    "    \"returns\": base_returns.copy(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "53ef7185-b08d-42e4-826a-66a446f8c695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure created_ts/last_updated_ts in baseline facts\n",
    "for t in [\"orders\", \"order_items\", \"payments\", \"shipments\", \"returns\"]:\n",
    "    if \"created_ts\" not in facts[t].columns:\n",
    "        facts[t][\"created_ts\"] = pd.Timestamp(\"2017-01-01\")\n",
    "    if \"last_updated_ts\" not in facts[t].columns:\n",
    "        facts[t][\"last_updated_ts\"] = pd.Timestamp(\"2017-01-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "4a3e1a93-2162-4a10-a7dc-9b987b2d157b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def pick_ids(series: pd.Series, frac: float) -> List[str]:\n",
    "    n = int(len(series) * frac)\n",
    "    n = max(0, n)\n",
    "    if n == 0:\n",
    "        return []\n",
    "    return series.sample(n=min(n, len(series)), replace=False).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "c4414f5b-9f6f-4393-839c-c75e67fb7394",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def mutate_customers(customers: pd.DataFrame, addresses: pd.DataFrame, accounts: pd.DataFrame, cfg: GenConfig, day: date\n",
    "                     ) -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      updated customers, addresses, accounts,\n",
    "      delta_customers, delta_addresses, delta_accounts\n",
    "    \"\"\"\n",
    "    customers = customers.copy()\n",
    "    addresses = addresses.copy()\n",
    "    accounts = accounts.copy()\n",
    "\n",
    "    delta_customers = []\n",
    "    delta_addresses = []\n",
    "    delta_accounts = []\n",
    "\n",
    "    # CHANGES\n",
    "    change_ids = pick_ids(customers[\"customer_id\"], cfg.customer_change_rate)\n",
    "    if change_ids:\n",
    "        c_mask = customers[\"customer_id\"].isin(change_ids)\n",
    "        # change city/state sometimes\n",
    "        customers.loc[c_mask, \"customer_city\"] = [fake.city().lower() for _ in range(c_mask.sum())]\n",
    "        customers.loc[c_mask, \"customer_state\"] = np.random.choice([\"SP\",\"RJ\",\"MG\",\"RS\",\"PR\",\"SC\",\"BA\",\"DF\",\"GO\"], size=c_mask.sum())\n",
    "        customers.loc[c_mask, \"last_updated_ts\"] = pd.Timestamp(day)\n",
    "\n",
    "        # addresses follow\n",
    "        a_mask = addresses[\"customer_id\"].isin(change_ids)\n",
    "        addresses.loc[a_mask, \"city\"] = [fake.city().lower() for _ in range(a_mask.sum())]\n",
    "        addresses.loc[a_mask, \"state\"] = np.random.choice([\"SP\",\"RJ\",\"MG\",\"RS\",\"PR\",\"SC\",\"BA\",\"DF\",\"GO\"], size=a_mask.sum())\n",
    "        addresses.loc[a_mask, \"last_updated_ts\"] = pd.Timestamp(day)\n",
    "\n",
    "        # account segment/status changes\n",
    "        acc_mask = accounts[\"customer_id\"].isin(change_ids)\n",
    "        if acc_mask.any():\n",
    "            accounts.loc[acc_mask, \"account_status\"] = np.random.choice([\"ACTIVE\", \"ACTIVE\", \"ACTIVE\", \"SUSPENDED\"], size=acc_mask.sum())\n",
    "            accounts.loc[acc_mask, \"last_updated_ts\"] = pd.Timestamp(day)\n",
    "\n",
    "        delta_customers.append(customers.loc[c_mask].assign(op=\"C\", event_dt=str(day)))\n",
    "        delta_addresses.append(addresses.loc[a_mask].assign(op=\"C\", event_dt=str(day)))\n",
    "        delta_accounts.append(accounts.loc[acc_mask].assign(op=\"C\", event_dt=str(day)))\n",
    "\n",
    "    # DELETES (soft: remove from snapshot; emit D in delta)\n",
    "    delete_ids = pick_ids(customers[\"customer_id\"], cfg.customer_delete_rate)\n",
    "    if delete_ids:\n",
    "        # emit delta rows (minimal keys is fine, but we include full record for convenience)\n",
    "        d_c = customers[customers[\"customer_id\"].isin(delete_ids)].copy()\n",
    "        d_a = addresses[addresses[\"customer_id\"].isin(delete_ids)].copy()\n",
    "        d_acc = accounts[accounts[\"customer_id\"].isin(delete_ids)].copy()\n",
    "\n",
    "        delta_customers.append(d_c.assign(op=\"D\", event_dt=str(day)))\n",
    "        delta_addresses.append(d_a.assign(op=\"D\", event_dt=str(day)))\n",
    "        delta_accounts.append(d_acc.assign(op=\"D\", event_dt=str(day)))\n",
    "\n",
    "        customers = customers[~customers[\"customer_id\"].isin(delete_ids)]\n",
    "        addresses = addresses[~addresses[\"customer_id\"].isin(delete_ids)]\n",
    "        accounts = accounts[~accounts[\"customer_id\"].isin(delete_ids)]\n",
    "\n",
    "    # INSERTS\n",
    "    ins_n = int(len(customers) * cfg.customer_insert_rate)\n",
    "    if ins_n > 0:\n",
    "        new_customers = []\n",
    "        new_addresses = []\n",
    "        new_accounts = []\n",
    "        for _ in range(ins_n):\n",
    "            cid = str(uuid.uuid4())\n",
    "            cust_unique = str(uuid.uuid4())\n",
    "            zip_prefix = random.randint(1000, 99999)\n",
    "            city = fake.city().lower()\n",
    "            state = random.choice([\"SP\",\"RJ\",\"MG\",\"RS\",\"PR\",\"SC\",\"BA\",\"DF\",\"GO\"])\n",
    "            new_customers.append({\n",
    "                \"customer_id\": cid,\n",
    "                \"customer_unique_id\": cust_unique,\n",
    "                \"customer_zip_code_prefix\": zip_prefix,\n",
    "                \"customer_city\": city,\n",
    "                \"customer_state\": state,\n",
    "                \"created_ts\": pd.Timestamp(day),\n",
    "                \"last_updated_ts\": pd.Timestamp(day),\n",
    "            })\n",
    "            aid = str(uuid.uuid4())\n",
    "            new_addresses.append({\n",
    "                \"address_id\": aid,\n",
    "                \"customer_id\": cid,\n",
    "                \"address_line1\": fake.street_address(),\n",
    "                \"address_line2\": fake.secondary_address(),\n",
    "                \"zip_code_prefix\": zip_prefix,\n",
    "                \"city\": city,\n",
    "                \"state\": state,\n",
    "                \"created_ts\": pd.Timestamp(day),\n",
    "                \"last_updated_ts\": pd.Timestamp(day),\n",
    "            })\n",
    "            new_accounts.append({\n",
    "                \"account_id\": str(uuid.uuid4()),\n",
    "                \"customer_id\": cid,\n",
    "                \"account_status\": \"ACTIVE\",\n",
    "                \"created_ts\": pd.Timestamp(day),\n",
    "                \"last_updated_ts\": pd.Timestamp(day),\n",
    "            })\n",
    "        new_cdf = pd.DataFrame(new_customers)\n",
    "        new_adf = pd.DataFrame(new_addresses)\n",
    "        new_accdf = pd.DataFrame(new_accounts)\n",
    "\n",
    "        customers = pd.concat([customers, new_cdf], ignore_index=True)\n",
    "        addresses = pd.concat([addresses, new_adf], ignore_index=True)\n",
    "        accounts = pd.concat([accounts, new_accdf], ignore_index=True)\n",
    "\n",
    "        delta_customers.append(new_cdf.assign(op=\"I\", event_dt=str(day)))\n",
    "        delta_addresses.append(new_adf.assign(op=\"I\", event_dt=str(day)))\n",
    "        delta_accounts.append(new_accdf.assign(op=\"I\", event_dt=str(day)))\n",
    "\n",
    "    dc = pd.concat(delta_customers, ignore_index=True) if delta_customers else pd.DataFrame()\n",
    "    da = pd.concat(delta_addresses, ignore_index=True) if delta_addresses else pd.DataFrame()\n",
    "    dacc = pd.concat(delta_accounts, ignore_index=True) if delta_accounts else pd.DataFrame()\n",
    "\n",
    "    return customers, addresses, accounts, dc, da, dacc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "fe4d5b60-87de-485e-b0bc-3d51acc97633",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def mutate_products(products: pd.DataFrame, cfg: GenConfig, day: date\n",
    "                    ) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    products = products.copy()\n",
    "    deltas = []\n",
    "\n",
    "    # Ensure timestamps exist\n",
    "    if \"created_ts\" not in products.columns:\n",
    "        products[\"created_ts\"] = pd.Timestamp(\"2017-01-01\")\n",
    "    if \"last_updated_ts\" not in products.columns:\n",
    "        products[\"last_updated_ts\"] = pd.Timestamp(\"2017-01-01\")\n",
    "\n",
    "    # CHANGES\n",
    "    change_ids = pick_ids(products[\"product_id\"], cfg.product_change_rate)\n",
    "    if change_ids:\n",
    "        m = products[\"product_id\"].isin(change_ids)\n",
    "        # tweak dimensions slightly (realistic corrections)\n",
    "        products.loc[m, \"product_weight_g\"] = (products.loc[m, \"product_weight_g\"].fillna(1000) * np.random.uniform(0.9, 1.1, size=m.sum())).round()\n",
    "        products.loc[m, \"product_length_cm\"] = (products.loc[m, \"product_length_cm\"].fillna(20) * np.random.uniform(0.9, 1.1, size=m.sum())).round()\n",
    "        products.loc[m, \"last_updated_ts\"] = pd.Timestamp(day)\n",
    "        deltas.append(products.loc[m].assign(op=\"C\", event_dt=str(day)))\n",
    "\n",
    "    # DELETES\n",
    "    delete_ids = pick_ids(products[\"product_id\"], cfg.product_delete_rate)\n",
    "    if delete_ids:\n",
    "        d = products[products[\"product_id\"].isin(delete_ids)].copy()\n",
    "        deltas.append(d.assign(op=\"D\", event_dt=str(day)))\n",
    "        products = products[~products[\"product_id\"].isin(delete_ids)]\n",
    "\n",
    "    # INSERTS\n",
    "    ins_n = int(len(products) * cfg.product_insert_rate)\n",
    "    if ins_n > 0:\n",
    "        new_rows = []\n",
    "        for _ in range(ins_n):\n",
    "            pid = str(uuid.uuid4())\n",
    "            new_rows.append({\n",
    "                \"product_id\": pid,\n",
    "                \"product_category_name\": random.choice(products[\"product_category_name\"].dropna().tolist()),\n",
    "                \"product_name_lenght\": random.randint(5, 60),\n",
    "                \"product_description_lenght\": random.randint(30, 1500),\n",
    "                \"product_photos_qty\": random.randint(1, 8),\n",
    "                \"product_weight_g\": random.randint(50, 5000),\n",
    "                \"product_length_cm\": random.randint(5, 120),\n",
    "                \"product_height_cm\": random.randint(2, 60),\n",
    "                \"product_width_cm\": random.randint(2, 80),\n",
    "                \"created_ts\": pd.Timestamp(day),\n",
    "                \"last_updated_ts\": pd.Timestamp(day),\n",
    "            })\n",
    "        new_df = pd.DataFrame(new_rows)\n",
    "        products = pd.concat([products, new_df], ignore_index=True)\n",
    "        deltas.append(new_df.assign(op=\"I\", event_dt=str(day)))\n",
    "\n",
    "    dp = pd.concat(deltas, ignore_index=True) if deltas else pd.DataFrame()\n",
    "    return products, dp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "382e695c-a33a-426e-b648-0ddc9919e6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ensure_dir(path: str) -> None:\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "\n",
    "def write_table(df: pd.DataFrame, path: str, fmt: str = \"csv\") -> None:\n",
    "    ensure_dir(path)\n",
    "    file_path = os.path.join(path, \"part-00000.csv\")\n",
    "    df.to_csv(file_path, index=False)\n",
    "\n",
    "\n",
    "def dt_path(root: str, kind: str, dt: date, table: str) -> str:\n",
    "    # kind: \"snapshots\" or \"deltas\"\n",
    "    return os.path.join(root, \"raw\", kind, f\"dt={dt.isoformat()}\", table)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7644c914-7742-4210-b5ca-13dd7df48322",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "cd849854-d2a3-431d-a872-38bf8cd25c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated day 2018-01-01 snapshots + deltas\n",
      "Generated day 2018-01-02 snapshots + deltas\n",
      "Generated day 2018-01-03 snapshots + deltas\n",
      "Generated day 2018-01-04 snapshots + deltas\n",
      "Generated day 2018-01-05 snapshots + deltas\n",
      "Generated day 2018-01-06 snapshots + deltas\n",
      "Generated day 2018-01-07 snapshots + deltas\n",
      "Generated day 2018-01-08 snapshots + deltas\n",
      "Generated day 2018-01-09 snapshots + deltas\n",
      "Generated day 2018-01-10 snapshots + deltas\n",
      "Generated day 2018-01-11 snapshots + deltas\n",
      "Generated day 2018-01-12 snapshots + deltas\n",
      "Generated day 2018-01-13 snapshots + deltas\n",
      "Generated day 2018-01-14 snapshots + deltas\n",
      "\n",
      "Done. Output at: /home/jovyan/work/Data Engineering/1. enterprise-grade batch analytics warehouse/output\n",
      "Example paths:\n",
      "  output/raw/snapshots/dt=2018-01-01/customers/part-00000.csv\n",
      "  output/raw/deltas/dt=2018-01-01/customers/part-00000.csv\n"
     ]
    }
   ],
   "source": [
    "root = cfg.out_dir\n",
    "ensure_dir(root)\n",
    "\n",
    "for i in range(cfg.num_days):\n",
    "    day = cfg.start_date + timedelta(days=i)\n",
    "\n",
    "    # ---- DIMS: mutate and produce deltas with op ----\n",
    "    cur[\"customers\"], cur[\"customer_addresses\"], cur[\"customer_accounts\"], dc, da, dacc = mutate_customers(\n",
    "        cur[\"customers\"], cur[\"customer_addresses\"], cur[\"customer_accounts\"], cfg, day\n",
    "    )\n",
    "    cur[\"products\"], dp = mutate_products(cur[\"products\"], cfg, day)\n",
    "\n",
    "    # Suppliers: optional small changes (keep stable for now)\n",
    "    dsup = pd.DataFrame()  # keep empty\n",
    "\n",
    "    # ---- FACTS: generate new daily facts (append-only) ----\n",
    "    new_orders, new_items, new_payments, new_shipments = generate_new_orders(\n",
    "        customers=cur[\"customers\"],\n",
    "        products=cur[\"products\"],\n",
    "        sellers=olist_data[\"sellers\"],\n",
    "        cfg=cfg,\n",
    "        day=day\n",
    "    )\n",
    "    new_returns = generate_returns_for_new_delivered(new_shipments, new_payments, cfg, day)\n",
    "\n",
    "    facts[\"orders\"] = pd.concat([facts[\"orders\"], new_orders], ignore_index=True)\n",
    "    facts[\"order_items\"] = pd.concat([facts[\"order_items\"], new_items], ignore_index=True)\n",
    "    facts[\"payments\"] = pd.concat([facts[\"payments\"], new_payments], ignore_index=True)\n",
    "    facts[\"shipments\"] = pd.concat([facts[\"shipments\"], new_shipments], ignore_index=True)\n",
    "    if not new_returns.empty:\n",
    "        facts[\"returns\"] = pd.concat([facts[\"returns\"], new_returns], ignore_index=True)\n",
    "\n",
    "    # ---- INVENTORY: update based on sales ----\n",
    "    cur[\"inventory\"], dinv = update_inventory_for_day(cur[\"inventory\"], new_items, cfg, day)\n",
    "\n",
    "    # ---- WRITE DAILY SNAPSHOTS (full dumps) ----\n",
    "    # Dims/state snapshots\n",
    "    for tbl in [\"customers\", \"customer_addresses\", \"customer_accounts\", \"products\", \"suppliers\", \"inventory\"]:\n",
    "        out = dt_path(root, \"snapshots\", day, tbl)\n",
    "        write_table(cur[tbl], out, cfg.file_format)\n",
    "\n",
    "    # Facts snapshots (optional full dump each day; enterprises sometimes do it)\n",
    "    # For your interview practice, it's useful to have daily full snapshots too.\n",
    "    for tbl in [\"orders\", \"order_items\", \"payments\", \"shipments\", \"returns\"]:\n",
    "        out = dt_path(root, \"snapshots\", day, tbl)\n",
    "        write_table(facts[tbl], out, cfg.file_format)\n",
    "\n",
    "    # ---- WRITE DAILY DELTAS (with op) ----\n",
    "    deltas: Dict[str, pd.DataFrame] = {\n",
    "        \"customers\": dc,\n",
    "        \"customer_addresses\": da,\n",
    "        \"customer_accounts\": dacc,\n",
    "        \"products\": dp,\n",
    "        \"suppliers\": dsup,\n",
    "        \"inventory\": dinv,\n",
    "        # Facts: treat all new rows as inserts\n",
    "        \"orders\": new_orders.assign(op=\"I\", event_dt=str(day)),\n",
    "        \"order_items\": new_items.assign(op=\"I\", event_dt=str(day)),\n",
    "        \"payments\": new_payments.assign(op=\"I\", event_dt=str(day)),\n",
    "        \"shipments\": new_shipments.assign(op=\"I\", event_dt=str(day)),\n",
    "        \"returns\": (new_returns.assign(op=\"I\", event_dt=str(day)) if not new_returns.empty else pd.DataFrame()),\n",
    "    }\n",
    "\n",
    "    for tbl, df in deltas.items():\n",
    "        out = dt_path(root, \"deltas\", day, tbl)\n",
    "        if df is None or df.empty:\n",
    "            # still create folder so pipelines don't break\n",
    "            ensure_dir(out)\n",
    "            # write an empty file with headers when possible\n",
    "            if tbl in cur:\n",
    "                empty = cur[tbl].head(0).copy()\n",
    "            elif tbl in facts:\n",
    "                empty = facts[tbl].head(0).copy()\n",
    "            else:\n",
    "                empty = pd.DataFrame()\n",
    "            if \"op\" not in empty.columns:\n",
    "                empty[\"op\"] = pd.Series(dtype=\"string\")\n",
    "            if \"event_dt\" not in empty.columns:\n",
    "                empty[\"event_dt\"] = pd.Series(dtype=\"string\")\n",
    "            write_table(empty, out, cfg.file_format)\n",
    "        else:\n",
    "            write_table(df, out, cfg.file_format)\n",
    "\n",
    "    print(f\"Generated day {day} snapshots + deltas\")\n",
    "\n",
    "print(f\"\\nDone. Output at: {os.path.abspath(root)}\")\n",
    "print(\"Example paths:\")\n",
    "print(f\"  {root}/raw/snapshots/dt={cfg.start_date.isoformat()}/customers/part-00000.csv\")\n",
    "print(f\"  {root}/raw/deltas/dt={cfg.start_date.isoformat()}/customers/part-00000.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "08381a4b-a9f4-4084-82da-ceb3bfb8b07c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order_delivered_customer_date   2018-10-17 13:22:46\n",
       "order_delivered_carrier_date    2018-09-11 19:48:28\n",
       "order_estimated_delivery_date   2018-11-12 00:00:00\n",
       "dtype: datetime64[us]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_orders[[\"order_delivered_customer_date\", \"order_delivered_carrier_date\", \"order_estimated_delivery_date\"]].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94172ab-754a-4cf8-8334-401123631721",
   "metadata": {},
   "source": [
    "# create s3 files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "05f08def-1ff7-491a-8062-ef518242a49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import awswrangler as wr\n",
    "\n",
    "client = boto3.client(service_name='secretsmanager')\n",
    "secret = client.get_secret_value(SecretId='test/secretsmanager')\n",
    "secret_dict = json.loads(secret['SecretString'])\n",
    "s3_bucket = secret_dict['s3_bucket']\n",
    "\n",
    "\n",
    "def dt_path_s3(root: str, kind: str, dt: date, table: str) -> str:\n",
    "    # kind: \"snapshots\" or \"deltas\"\n",
    "    return os.path.join(root, \"raw\", kind, table, f\"{dt.isoformat()}\")\n",
    "\n",
    "\n",
    "def write_table_s3(df:pd.DataFrame, path):\n",
    "    s3_path = f's3://{s3_bucket}/{path}/file.csv'\n",
    "    wr.s3.to_csv(df=df, path=s3_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "f321c5e3-d486-40c6-bfb4-0d90d9579aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated day 2019-01-01 snapshots + deltas\n",
      "Generated day 2019-01-02 snapshots + deltas\n",
      "Generated day 2019-01-03 snapshots + deltas\n",
      "Generated day 2019-01-04 snapshots + deltas\n",
      "Generated day 2019-01-05 snapshots + deltas\n",
      "Generated day 2019-01-06 snapshots + deltas\n",
      "Generated day 2019-01-07 snapshots + deltas\n",
      "Generated day 2019-01-08 snapshots + deltas\n",
      "Generated day 2019-01-09 snapshots + deltas\n",
      "Generated day 2019-01-10 snapshots + deltas\n",
      "Generated day 2019-01-11 snapshots + deltas\n",
      "Generated day 2019-01-12 snapshots + deltas\n",
      "Generated day 2019-01-13 snapshots + deltas\n",
      "Generated day 2019-01-14 snapshots + deltas\n",
      "Generated day 2019-01-15 snapshots + deltas\n",
      "\n",
      "Done. Output at: /home/jovyan/work/Data Engineering/1. enterprise-grade batch analytics warehouse/output\n",
      "Example paths:\n",
      "  output/raw/snapshots/customers/dt=2019-01-01/part-00000.csv\n",
      "  output/raw/deltas/customers/dt=2019-01-01/part-00000.csv\n"
     ]
    }
   ],
   "source": [
    "root = cfg.out_dir\n",
    "\n",
    "for i in range(cfg.num_days):\n",
    "    day = cfg.start_date + timedelta(days=i)\n",
    "\n",
    "    # ---- DIMS: mutate and produce deltas with op ----\n",
    "    cur[\"customers\"], cur[\"customer_addresses\"], cur[\"customer_accounts\"], dc, da, dacc = mutate_customers(\n",
    "        cur[\"customers\"], cur[\"customer_addresses\"], cur[\"customer_accounts\"], cfg, day\n",
    "    )\n",
    "    cur[\"products\"], dp = mutate_products(cur[\"products\"], cfg, day)\n",
    "\n",
    "    # Suppliers: optional small changes (keep stable for now)\n",
    "    dsup = pd.DataFrame()  # keep empty\n",
    "\n",
    "    # ---- FACTS: generate new daily facts (append-only) ----\n",
    "    new_orders, new_items, new_payments, new_shipments = generate_new_orders(\n",
    "        customers=cur[\"customers\"],\n",
    "        products=cur[\"products\"],\n",
    "        sellers=olist_data[\"sellers\"],\n",
    "        cfg=cfg,\n",
    "        day=day\n",
    "    )\n",
    "    new_returns = generate_returns_for_new_delivered(new_shipments, new_payments, cfg, day)\n",
    "\n",
    "    facts[\"orders\"] = pd.concat([facts[\"orders\"], new_orders], ignore_index=True)\n",
    "    facts[\"order_items\"] = pd.concat([facts[\"order_items\"], new_items], ignore_index=True)\n",
    "    facts[\"payments\"] = pd.concat([facts[\"payments\"], new_payments], ignore_index=True)\n",
    "    facts[\"shipments\"] = pd.concat([facts[\"shipments\"], new_shipments], ignore_index=True)\n",
    "    if not new_returns.empty:\n",
    "        facts[\"returns\"] = pd.concat([facts[\"returns\"], new_returns], ignore_index=True)\n",
    "\n",
    "    # ---- INVENTORY: update based on sales ----\n",
    "    cur[\"inventory\"], dinv = update_inventory_for_day(cur[\"inventory\"], new_items, cfg, day)\n",
    "\n",
    "    # ---- WRITE DAILY SNAPSHOTS (full dumps) ----\n",
    "    # Dims/state snapshots\n",
    "    for tbl in [\"customers\", \"customer_addresses\", \"customer_accounts\", \"products\", \"suppliers\", \"inventory\"]:\n",
    "        out = dt_path_s3(root, \"snapshots\", day, tbl)\n",
    "        write_table_s3(cur[tbl], out)\n",
    "\n",
    "    # Facts snapshots (optional full dump each day; enterprises sometimes do it)\n",
    "    # For your interview practice, it's useful to have daily full snapshots too.\n",
    "    for tbl in [\"orders\", \"order_items\", \"payments\", \"shipments\", \"returns\"]:\n",
    "        out = dt_path_s3(root, \"snapshots\", day, tbl)\n",
    "        write_table_s3(facts[tbl], out)\n",
    "\n",
    "    # ---- WRITE DAILY DELTAS (with op) ----\n",
    "    deltas: Dict[str, pd.DataFrame] = {\n",
    "        \"customers\": dc,\n",
    "        \"customer_addresses\": da,\n",
    "        \"customer_accounts\": dacc,\n",
    "        \"products\": dp,\n",
    "        \"suppliers\": dsup,\n",
    "        \"inventory\": dinv,\n",
    "        # Facts: treat all new rows as inserts\n",
    "        \"orders\": new_orders.assign(op=\"I\", event_dt=str(day)),\n",
    "        \"order_items\": new_items.assign(op=\"I\", event_dt=str(day)),\n",
    "        \"payments\": new_payments.assign(op=\"I\", event_dt=str(day)),\n",
    "        \"shipments\": new_shipments.assign(op=\"I\", event_dt=str(day)),\n",
    "        \"returns\": (new_returns.assign(op=\"I\", event_dt=str(day)) if not new_returns.empty else pd.DataFrame()),\n",
    "    }\n",
    "\n",
    "    for tbl, df in deltas.items():\n",
    "        out = dt_path_s3(root, \"deltas\", day, tbl)\n",
    "        if df is None or df.empty:\n",
    "            # still create folder so pipelines don't break\n",
    "            ensure_dir(out)\n",
    "            # write an empty file with headers when possible\n",
    "            if tbl in cur:\n",
    "                empty = cur[tbl].head(0).copy()\n",
    "            elif tbl in facts:\n",
    "                empty = facts[tbl].head(0).copy()\n",
    "            else:\n",
    "                empty = pd.DataFrame()\n",
    "            if \"op\" not in empty.columns:\n",
    "                empty[\"op\"] = pd.Series(dtype=\"string\")\n",
    "            if \"event_dt\" not in empty.columns:\n",
    "                empty[\"event_dt\"] = pd.Series(dtype=\"string\")\n",
    "            write_table_s3(empty, out)\n",
    "        else:\n",
    "            write_table_s3(df, out)\n",
    "\n",
    "    print(f\"Generated day {day} snapshots + deltas\")\n",
    "\n",
    "print(f\"\\nDone. Output at: {os.path.abspath(root)}\")\n",
    "print(\"Example paths:\")\n",
    "print(f\"  {root}/raw/snapshots/customers/dt={cfg.start_date.isoformat()}/part-00000.csv\")\n",
    "print(f\"  {root}/raw/deltas/customers/dt={cfg.start_date.isoformat()}/part-00000.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30cb1fc-0cdc-493c-be9f-f8c0cacb626a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8d3734-26af-46b3-bd5d-484c5e4a2022",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c6c816-0280-4a99-8b28-4940358c4d3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
